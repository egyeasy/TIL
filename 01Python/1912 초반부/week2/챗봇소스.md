



<환율>

```python
# 이 코드는 숨겨져 있지롱~

import requests
from bs4 import BeautifulSoup

url = 'https://earthquake.kr:23490/'

response = requests.get(url).text

print(response)
#print('현재 원/달러 환율은 {0}원/달러입니다.'.format(response["USDKRW"][0])
```





<점심메뉴>

```python
import random

menu = ["순남시레기", "멀티캠퍼스 20층", "양자강", "강남목장", "시골집"]
menu_detail = {"순남시레기": "시레기국, 보쌈", "멀티캠퍼스 20층": "오늘의 메뉴",
               "양자강": "차돌짬뽕", "강남목장": "뚝배기불고기", "시골집": "쌈밥정식"}

select = random.randrange(0, 5)
lunch = menu[select]

choice = random.choice(menu)
print(choice)

print(random.sample(range(5), 2))

select_menu = menu_detail[lunch]
last = select_menu[-1]

if (last == "뉴" or last == "기"):
  print(lunch + "에서는 " + select_menu + "가 먹을 만합니다.")  
else:
  print(lunch + "에서는 " + select_menu + "이 먹을 만합니다.")
```





<미세먼지>

```python
import requests
from bs4 import BeautifulSoup

url = 'http://openapi.airkorea.or.kr/openapi/services/rest/ArpltnInforInqireSvc/getCtprvnRltmMesureDnsty?sidoName=%EC%84%9C%EC%9A%B8&ServiceKey={}&ver=1.3&pageNo=3'.format(key)
response = requests.get(url).text
soup = BeautifulSoup(response, 'xml')
gn = soup('item')[7]
location = gn.stationName.text
time = gn.dataTime.text
dust = int(gn.pm10Value.text)

print(gn.stationName.text)

print('{0} 기준: 서울시 {1}의 미세먼지 농도는 {2} 입니다.'.format(time, location, dust))

# &&는 앞에거 false면 뒤에거 안봄. &는 뒤에 거도 같이 보고 체크한다.

# 조건문
condition = ""
if (dust > 150):
  condition = "매우 나쁨"
  
elif (80 < dust <= 150):
  condition = "나쁨"

elif (30 < dust <= 80):
  condition = "보통"

else:
  condition = "좋음"
  
print('{0} 기준: 서울시 {1}의 미세먼지 농도는 {2} 입니다.'.format(time, location, condition))

```



<먹보>

```python
dish = ["삼겹살", "꽃등심", "파스타", "뚝배기 불고기", "폭찹"]

# 1. for문을 이용해서 dish에 담겨있는 모든 음식을 먹는 코드를 작성
for food in dish:
  print("{}를 먹었습니다.".format(food))

# 2. while문을 이용해서 dish에 담겨있는 모든 음식을 두번씩 먹는 코드를 작성
num_of_eat = 0
while (num_of_eat != 2):
  for i in dish:
    print(i + "를 먹었습니다.")
  num_of_eat += 1
```





<환율2>

```python
import requests
from bs4 import BeautifulSoup

url = 'https://earthquake.kr:23490/'

response = requests.get(url).json()
nation_dic = {'호주': 'AUDKRW', '캐나다': 'CADKRW', '중국': 'CNYKRW', '유로': 'EURKRW',
           '일본': 'JPYKRW', '미국': 'USDKRW'}

#print(response)
for nation in nation_dic.keys():
  print('현재 {0} 환율은 {1} KRW/{2}입니다.'.format(nation, response[nation_dic[nation]][0],
                                          nation_dic[nation][:3]))
```





<날씨>

```python
import requests

url = "https://api.openweathermap.org/data/2.5/weather?q=Seoul,kr&lang=kr&APPID="+key

data = requests.get(url).json()

weather = data['weather'][0]['description']
temp = float(data['main']['temp'])-273.15
temp_min = float(data['main']['temp_min'])-273.15
temp_max = float(data['main']['temp_max'])-273.15

#풍속, 가시거리
wind = float(data['wind']['speed'])
visibility = data['visibility']

print("""서울의 오늘 날씨는 [{}] 이며, 섭씨 {:.1f}도 입니다.
최저/최고 온도는 {:.1f}/{:.1f}도 입니다.
현재 풍속은 {:.1f}m/s이며 가시거리는 {}m 입니다.
""".format(weather, temp, temp_min, temp_max, wind, visibility)
)
```





<로또>

```python
import random

# 1~45까지의 숫자를 가진 numbers라는 배열을 만든다.
# python make long array / make number array
numbers = list(range(1, 46))
print(numbers)

# numbers에서 숫자 6개를 랜덤으로 뽑는다.(당연히 비복원 추출)
# 랜덤으로 뽑은 숫자들을 lotto 변수에 담고 출력한다.
lotto = random.sample(numbers, 6)
print(lotto)
# 추가: lotto 변수에 담겨있는 숫자들을 오름차순으로 정렬하기
lotto.sort()
print(lotto)
```



<로또번호>

```python
import requests as req
import random
from bs4 import BeautifulSoup as bs

url = 'https://m.dhlottery.co.kr/common.do?method=main'
response = req.get(url).text
#print(response)
soup = bs(response, 'html.parser')

document = soup.select('.prizeresult')[0]

numbers = document.select('span')
ns = []
for number in numbers:
  ns.append(int(number.text))

ns.sort()

lotto = sorted(random.sample(list(range(1,46)),6))
print(lotto, ns)

# 지난 주 당첨 숫자 list를 한번씩 순회하면서
# 내가 뽑아놓은 lotto list에서 
# 몇개가 맞았는지 카운트 하기
count = 0
for i in ns:
  if i in lotto:
    count += 1;
print(count)
```



<네이버웹툰>

```python
import requests
import time
from bs4 import BeautifulSoup as bs

# 1. 네이버 웹툰을 가져올 수 있는 주소(url)을 파악하고 url 변수에 저장한다.
today = time.strftime("%a").lower()
print(today)
url = 'https://comic.naver.com/webtoon/weekdayList.nhn?week='+today

# 2. 해당 주소로 요청을 보내 정보를 가져온다.
response = requests.get(url).text

# 3. 받은 정보를 bs를 이용해 검색하기 좋게 만든다.
soup = bs(response, 'html.parser')
# 4. 네이버 웹툰 페이지로 가서, 내가 원하는 정보가 어디에 있는지 파악한다.
# 내가 원하는 정보는 웹툰을 볼 수 있는 링크, 웹툰의 제목 + 해당 웹툰의 썸네일(이미지의 주소)
toons = []

li = soup.select('.img_list li')
for item in li:
  toon = [
    {"title": item.select_one('dt a').text,
     "url": item.select('dt a')[0]["href"],
     "img_url": item.select('.thumb img')[0]["src"]}
  ]
  toons.append(toon)

print(toons)
  
  
#print(li)

#print(a_tags)
# 5. 3번에서 저장한 문서를 이용해 4번에서 파악한 정보의 위치를 뽑아내는 코드를 작성한다.

# 6. 출력한다.
```



<다음웹툰>

```python
import requests
import time
import json
from bs4 import BeautifulSoup as bs

# 1. 내가 원하는 정보를 얻을 수 있는 주소를 url이라고 하는 변수에 담는다.
today = time.strftime("%a").lower()
url = 'http://webtoon.daum.net/data/pc/webtoon/list_serialized/'+today+'?'

# 2. 해당 url에 요청을 보내 응답을 받아 저장한다.
response = requests.get(url).json()

# 3. 구글신에게 파이썬으로 어떻게 json을 파싱(딕셔너리 형으로 변환)하는지 물어본다.
# 4. 파싱한다.(변환한다)
# 5. 내가 원하는 데이터를 꺼내서 조합한다.
toons = response['data']
for toon in toons:
  toon_url = 'http://webtoon.daum.net/webtoon/view/'+ toon['nickname']
  print("제목: "+ toon['title'],"\nurl: "+ toon_url,"\n이미지url: "+ toon['thumbnailImage2']['url'],"\n")
```

