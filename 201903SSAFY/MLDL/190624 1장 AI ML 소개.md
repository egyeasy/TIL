# 190624 1장 AI/ML 소개

머신러닝은 빅데이터를 분석, 이해, 예측하는 한 방법



#### ML vs 데이터마이닝

머신러닝은 structured data(정형 데이터)가 필요 x, 데이터마이닝은 필요



#### ML vs AI

ML은 AI 중에서 data-dependent한 방법



#### ML vs Statistics

ML is deeply rooted in but expands the practical limitations of Statistics



### 지도 학습(supervised learning)

- 크게 선형 모델과 비선형 모델로 나뉨
- 비선형 모델의 하나 - Decision Tree
- 데이터에 대해 정답(label)을 알고 있어야 함 - 데이터를 구하기 어려운 문제



### 비지도 학습(unsupervised learning)

- label이 없는 데이터

- K-means clustering - 간단한 설명을 위해 2차원 데이터 사용

  가까이 있는 것들은 비슷한 그룹일 것이라는 가정

  '가까이'라는 기준에 대해 의문이 생길 수 있음 -> 다르게 나누는 게 더 합리적인 경우가 있다.(DB Scan)

  DB-scan - 임의의 데이터 포인트 1개에서 시작해서 가까이 있는 점들로 점의 세력을 만들어나가는 것. 하나의 세력이 끝나면 새로운 포인트에서 새로운 세력을 만들기 시작.

  

### Representation Learning

초창기에는 선 찾기 알고리즘, 곡선 찾기 알고리즘, 타원 찾기 알고리즘, 눈 찾기 알고리즘 등등을 만들어서 이미지를 인식했다. 하지만 NN이 나오면서 한방에 다 해결할 수 있게 되어서 representation learning이라 불림.

- Reducing the Dimensionality of Data with Neural Networks(Hinton, 2006)

  데이터 사이즈가 매우 커졌다. - 차원을 좀 줄일 필요가 있다. 의미가 있는 것은 남겨두고, 의미 없는 것은 ㄷ없애야 하는데 그것이 NN으로 가능하다는 게 논문의 요지.

- Different Levels of Abstraction(Andrew Ng, 2014)

  layer 1 : 픽셀별 흑백 학습

  layer 2 : 픽셀들을 연결시켜 선을 학습(edges and simple shapes)

  layer 3 : 눈, 코, 입 등 복잡한 shape 학습

  layer 4 : 얼굴 학습

- why now?

  1. Complexity of model is very high - requires huge datasets, advanced hardware with fast processors, large memory, high I/O speed
  2. Model is prone to overfitting - advanced algorithms to overcome overfitting are needed(Hinton의 dropout 등)
  3. parameter estimation is difficult - clever modifications to the model, as well as advanced algorithms  to estimate parameters more quickly



### Famous AI Systems - AI를 이용해서 활용할 수 있는 것

- IBM Deepblue(1997) - 방 하나에 들어갈 만한 큰 컴퓨터. 체스 그랜드마스터를 이김
- 자율주행(2007) - urban challenge라는 대회에서 실제 도시와 같은 환경(보행자, 사람이 운전하는 차)에서 MIT 팀이 성공적으로 운행
- IBM Research Watson(2011) - Jeopardy라는 퀴즈쇼에서 유명해짐. 지식, 속담 등 사람의 언어를 꽤 이해해야 풀 수 있는 퀴즈쇼. 사람을 대상으로 한 경쟁에서 이김.
- Deepmind alphago(2016)
- AlphaGo Zero(2017) - 2016은 fair하지 않았다. 기보를 몇 만 개 학습해서 잘하게 된 것. 이건 사람의 학습량보다 훨씬 많은 양으로 학습한 것. 2017년에는 학습 데이터가 하나도 주어지지 않았다. 자기 자신과 대결하며 학습하는 것. 바둑의 룰만 알지만 나머지 지식은 0. 3일이 지나면 2016년 버전과 비슷해짐. 21일이 지나면 프로 바둑기사 60명을 항상 이길 수 있게 됨.
- Google Duplex(2018) - 클로바와 같은 시스템. 범용 챗봇이 아니라 비즈니스용. 미용실을 운영하면 미용실 챗봇. 실제로 대화를 해서 예약을 할 수 있음. User가 google assistant에게 말을 하면 이걸 duplex에게 전달해서 답을 알아냄.



### AI 응용분야와 데이터셋

- Visual intelligence(Computer Vision)
  - MNIST 숫자필기인식.
  - ImageNet - 몇 천 개의 클래스(포유류 - 강아지 - 허스키 등 위계구조를 가진 분류체계). 아직도 정확도를 올리는 연구가 계속되고 있음. 데이터가 적은 클래스에 대해서도 분류를 해야 하는 과제, transfer learning 과제 등이 남아있음.
- Language Intelligence
  - Q&A task - 정보를 주고 그것에 대해 질의응답을 할 수 있는지. dataset은 Stanford SQUAD(2018)
  - Machine Translation - 구글이 대표적. language에서 dataset은 corpus라고 한다. 예전처럼 주어 동사 등을 따지지는 않는 방식 -> 요즘은 parallel corpus(같은 내용을 한국어 영어로 되어있는 것)를 가지고 학습을 함. EU의 political document가 대표적. UN parallel corpus, wikipedia parallel corpus도 있음.
  - GLUE - 좀 더 디테일한 문제를 풀기 위한 dataset. 9개의 주요 질문에 응답하기 위함(e.g. 이 문장이 문법적으로 맞냐. 이 문장에서 주장하는 것?)