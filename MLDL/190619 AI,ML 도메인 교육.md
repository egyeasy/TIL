# 190619 AI / ML 도메인 교육

### 프로젝트 개요

#### 목표

1. AI/ML의 전반적인 이해
2. 딥러닝 기반의 자연어 처리기능을 갖는 챗봇 구현
3. 팀 프로젝트를 통한 협업으로 확장된 기능 구현



## 지도 학습

Label이 있는 학습 데이터를 이용해서 학습

1. 분류(Classification)

   결과 : 학습데이터의 레이블 중 하나를 예측(discrete)

   예제 : 학습데이터가 A, B, C인 경우 결과는 A, B, C 중 하나다.

2. 회귀(Regression)

   연속된 값을 예측(Continuous)

   결과 값이 어떠한 값도 나올 수 있다. 예) 주가 분석 예측



## 비지도 학습

Label이 없는 학습 데이터를 이용해서 학습

|        | 분류(Classification) | 군집(Clustering)                                             |
| ------ | -------------------- | ------------------------------------------------------------ |
| 공통점 |                      |                                                              |
| 차이점 | 레이블이 있다.       | 레이블이 없다.<br />예) 의학 임살실험 환자군 구별,<br />구매자 유형 분류 |

- 군집합(Clustering)

  비슷한 특성을 갖는 데이터로 묶기

  레이블을 없애고 학습시킨 후 얼마나 잘 맞추는지를 검증해보는 방법도 있다.

- 이상 탐지(Anomaly detection)

  기존 데이터 패턴과 다른 이상치 검출

- 시각화(Visualization)

  데이터의 특성을 시각화하여 데이터들의 패턴 연구

- 차원 축소(Dimensionality reduction)

  상관관계가 있는 여러 특성을 하나로 합침 -> 중요한 특성을 쉽게 봄



## 강화 학습

어떤 환경 안에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법이다.

중요한 것 -> 리워드를 어떻게 모델링할 것인가?



### 과적합(Overfitting)

학습 데이터에 너무 지나치게 맞추다 보면 일반화 성능이 떨어지는 모델을 얻게 되는 현상





## 자연어 처리

#### 자연어 전처리 과정

1. Noise canceling

   스펠링 체크 및 띄어쓰기 오류 교정

2. Tokenizing

   문장을 토큰으로 나눔, 토큰은 n-gram, 어절, 단어 등 목적에 다라 다르게 정의

3. Part-of-Speech tagging

   주어진 토큰의 품사 판별

4. Filtering; stopwords removal

   불필요한 단어 제거

5. Term vector representation

   (문서, 단어) 행렬에서 각 단어의 중요도를 조절

6. Transformation

   TF-IDF 등의 방식으로 term vector 변환 - 너무 자주 쓰이는 단어는 오히려 의미가 없는 단어다





## 딥 러닝(Deep Learning)

#### 딥러닝의 정의

컴퓨터가 스스로 학습할 수 있게 하기 위해 인공 신경망을 기반으로 하는 기계학습 기술

인간의 신경망(Neural Network) 이론을 이용한 인공 신경망(ANN, Artificial Neural Network)의 일종

현재 다음 두 분야에서 핫함

1. computer vision
2. speech & audio
3. NLP



### 딥러닝의 발전 과정 및 이론적 기초

#### 퍼셉트론(perceptron)

초기 퍼셉트론으로 XOR 문제를 해결할 수 없었던 문제.

-> 다층 퍼셉트론으로 XOR 연산 가능

​	여전히 남은 문제점

	1. 비선형 분류의 어려움
 	2. 다층으로 쌓아올린 퍼셉트론의 학습 방법 부재

-> 빙하기 돌입



#### Back Propagation

뒷단부터 가중치를 업데이트

- 기존의 학습 방법
  - 인풋에 대한 아웃풋과 실제 데이터와의 오차를 최적화
  - 은닉층의 존재로 정방향(feedforward)으로 오차를 업데이트 불가능
- 역방향으로 오차를 전파
  - 아웃풋과 실제 데이터와의 오차를 가중치로 미분해서 최적화
  - 미분을 위해서 activation function -> sigmoid function or relu 등등



#### 현재 딥러닝 오기까지

- 알고리즘의 개선
  - MLP
  - Backpropagation
  - Vanishing gradient solution
- 하드웨어의 개선
  - GPU
- 빅데이터
  - 소규모 데이터에서는 과적합만 발생











































