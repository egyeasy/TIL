```python
import requests
from bs4 import BeautifulSoup

url = 'http://openapi.airkorea.or.kr/openapi/services/rest/ArpltnInforInqireSvc/getCtprvnRltmMesureDnsty?sidoName=%EC%84%9C%EC%9A%B8&ServiceKey={}&ver=1.3&pageNo=3'.format(key)
response = requests.get(url).text #원하는 주소로 요청을 보내고 받은 응답의 내용만 response에 담음
soup = BeautifulSoup(response, 'xml') # ctrl+f 누르고 찾을 준비
gn = soup('item')[7] # 검색 'item' 태그의 8번째
location = gn.stationName.text
time = gn.dataTime.text
dust = int(gn.pm10Value.text)
```



원하는 부분 elements > 우클릭 > copy > copy selector 누르면 복사됨

#boxIndexes > div:nth-child(1) > span.num.down > strong



network > finance.daum.net > response or preview > 원래 페이지와 아예 다르다. 여기에 없는 정보는 js가 다른 곳에서 쏴서 보내주기 때문



검색 방식:

id : #아이디 이름
class : .클래스이름
속성 : ["속성 종류"] dictionary처럼 접근





```python
{"title": item.select('dt a')[0].text, #속성명을 뽑아오기
 "url": item.select('dt a')[0]["href"], #속성값을 뽑아오기
```
select는 무조건 복수를 가져다주기 때문에 list 안의 요소를 선택하기 위해 [0]을 붙여줘야 한다.

select_one('dt a') = select('dt a')[0]



페이지 로딩되는 동안 network 탭에서 로딩되는 정보들을 살펴볼 수 있다 -> json인지 확인

